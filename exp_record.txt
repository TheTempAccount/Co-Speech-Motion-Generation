2021/12/06
    exp_2_man_four_concat 这个模型实际上是add的。感觉存在的问题是，由于没有使用conf，结果出现没有检测出关键点的失败情形。另外倾向于乱动，没有停顿，控制力有点弱。可能存在的原因是1. content_dim是0, 2. 数据，不是之前版本的 3. 没有l0 4. 模型结构和之前不一样 5. normalization?

    exp_3_1: 添加了conf，添加了content dim
    手部关键点的丢失倒是看不到了，但是感觉有不正常的运动，可能是decoder的缘故？错误累计导致的可能是。在原repo中尝试复现，调小aud的weight
    
    第一次训练的是没有conf的和之前模型对齐的参数，但是仍然存在不自然的运动，可能是decoder的累计导致的

    freeMo的模型更改，修改成原始repo的那种用dec_style作为模型的输入

    exp_3_2：aud_weight=1的时候，即使将dec修改回去了，仍然出现不自然的手部运动。似乎是

    exp_3_2_1: aud_weight = 0.1， 看起来不自然的手部运动好了很多。但是存在的问题是控制力依然不够，看起来一直在乱动，可能是KL的问题，增大KL的权重进行尝试

    经过仔细对比之后，结论是aud_weight=0.1的缘故。但是dec的影响有没有很难说

    重新将dec修改成了之前的结构，递归式的训练，增大KL权重，

    原始的repro中，很难与exp_3_2_1有一个鲜明的对比，exp_3_2_1可能比较正常了。还存在的原因可能是mfcc和mel的不同。
    原始的repo中，aud_weight=1时，状况比这里要好，但是可能也存在一些不自然的抖动

    exp_4_1：修改回dec之后，在完全相同的参数设置下进行对比. 不是很好确定，手部的不自然的抖动看起来更加严重一些。叠加形式造成的影响似乎还是存在的

    exp_4_2: 增大KL权重，看能否有更好的限制。转换很少，diversity受限可能很严重

    exp_4_3: 取消content，增加层数，缩减embedding的规模。

    exp_4_4: 更改为concat的形式。似乎diversity要好一些。

    原始的模型：看起来还是更好一些，没有乱动的感觉。现在存在的问题是，kl小的话有点乱动，kl大则diversity受限

    对比之下，固定的decoder输出比较好，KL等于0.001比0.01要好。
    实验计划：
    1. 复现MT-VAE的数据。这个可以和MT-VAE的模型结构进行对比下。

    2. KL=0.001, 原始的dec. 这个似乎和原来的比较接近。用这个来占用GPU吧

        2.1 更改add为concat
        2.2 KL=0.01, aud=1的情形
        2.3 取消content，增加层数，缩减embedding的规模
        2.4 直接取消KL loss，在训练的时候就从0,1中采样

    3. 全卷积形式的模型结构。其次

    4. old版本尽可能复现出原来的，能够加载原来的参数为好(首要！)。然后把原来的git弄好一点，这个这周完成

    其他的：重新生成更好的标注，检查video clip的质量
    其他模型的检查。能不能复现倒不是很重要，不会在代码里面被显然地挑出错误即可
    3D的标注生成
    2D关键点的learning的理解。KL权重的不同导致的行为差异值得探索
    图结构、adversial learning等需要理解
    模型结构继续写吧